{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9622cc17-a6a5-4643-bba7-3815be302872",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -c \"import monai\" || pip install -q \"monai-weekly[gdown, nibabel, tqdm, ignite]\"\n",
    "!python -c \"import matplotlib\" || pip install -q matplotlib\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40160142-75fb-4ca2-bfd0-2c3a37d1678b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root directory: /tmp/tmpy4so1vf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/app-root/lib64/python3.9/site-packages/torch/jit/_trace.py:1001: TracerWarning: Output nr 1. of the traced function does not match the corresponding output of the Python function. Detailed error:\n",
      "Tensor-likes are not close!\n",
      "\n",
      "Mismatched elements: 836 / 1769472 (0.0%)\n",
      "Greatest absolute difference: 8.803606033325195e-05 at index (0, 1, 67, 31, 79) (up to 1e-05 allowed)\n",
      "Greatest relative difference: 0.04067104894233465 at index (0, 0, 67, 31, 82) (up to 1e-05 allowed)\n",
      "  _check_trace(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traced model converted to ONNX successfully.\n",
      "ONNX file saved at: /tmp/tmpy4so1vf5/spleen_seg_model.onnx\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from monai.networks.nets import UNet\n",
    "from monai.transforms import (\n",
    "    LoadImaged,\n",
    "    EnsureChannelFirstd,\n",
    "    Orientationd,\n",
    "    Spacingd,\n",
    "    ScaleIntensityRanged,\n",
    "    CropForegroundd,\n",
    "    Compose,\n",
    ")\n",
    "from monai.data import Dataset, DataLoader\n",
    "\n",
    "# Use the provided directory as root_dir\n",
    "root_dir = \"/tmp/tmp8oke_gi_\"\n",
    "\n",
    "print(\"Root directory:\", root_dir)\n",
    "\n",
    "# Define your model architecture\n",
    "device = torch.device(\"cuda:0\")\n",
    "model = UNet(\n",
    "    spatial_dims=3,\n",
    "    in_channels=1,\n",
    "    out_channels=2,\n",
    "    channels=(16, 32, 64, 128, 256),\n",
    "    strides=(2, 2, 2, 2),\n",
    "    num_res_units=2,\n",
    "    norm=\"batch\",\n",
    ").to(device)\n",
    "\n",
    "# Load the trained model weights\n",
    "model.load_state_dict(torch.load(os.path.join(root_dir, \"best_metric_model.pth\")))\n",
    "model.eval()\n",
    "\n",
    "# Define example input\n",
    "random_input = torch.randn(1, 1, 96, 96, 96).to(device)  # Adjust the shape according to your input\n",
    "\n",
    "# Trace the model\n",
    "traced_model = torch.jit.trace(model, random_input)\n",
    "\n",
    "# Save the traced model to ONNX format\n",
    "onnx_file_path = os.path.join(root_dir, \"spleen_seg_model.onnx\")\n",
    "torch.onnx.export(\n",
    "    traced_model,\n",
    "    example_input,\n",
    "    onnx_file_path,\n",
    "    export_params=True,\n",
    "    opset_version=11,\n",
    "    do_constant_folding=True,\n",
    ")\n",
    "\n",
    "print(\"Traced model converted to ONNX successfully.\")\n",
    "\n",
    "print(\"ONNX file saved at:\", onnx_file_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
