{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604723aa-b0d0-49d4-81a8-9332c7e601bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install scikit-image nibabel monai onnxruntime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c06e224-7916-4b95-ab14-37ebd2e2b761",
   "metadata": {},
   "source": [
    "# Testing the Model Deployment\n",
    "\n",
    "After deploying the model using RHOAI Model Serving, we'd like to test the model deployment by sending images to the model server for real-time inference.\n",
    "\n",
    "In this notebook we'll review how to consume the model through the RHOAI Model Server.\n",
    "\n",
    "We'll start by importing the preprocessing and rendering functions that we have worked with in the previous notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd48db30-205c-4458-8f84-2e55599db6a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from time import sleep\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from monai.inferers import sliding_window_inference\n",
    "from requests import post\n",
    "from skimage.transform import resize\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88027c49-fbe2-4a72-ac46-266ab0becbb6",
   "metadata": {},
   "source": [
    "Let's prepare one of our sample images as a test sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ffad01-a4cc-4d96-b725-309655636768",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prediction_url = 'https://spleen-v7-spleen.apps.rhods-internal.61tk.p1.openshiftapps.com/v2/models/spleen-v7/infer'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52cdc026-6119-4749-ab98-44d1828e64ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def serialize(image):\n",
    "    payload = {\n",
    "        'inputs': [\n",
    "            {\n",
    "                'name': 'x',\n",
    "                'shape': [1, 1, 96, 96, 96],\n",
    "                'datatype': 'FP32',\n",
    "                'data': image,\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "    return payload"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d859e1-f9d1-4801-be38-8db71cf8e31e",
   "metadata": {},
   "source": [
    "Let's now send the serialized image to the model server. The inference results will also be returned in a generic JSON structure, which we can unpack straightaway. We'll also apply the post-processing function we defined in the previous notebook to extract the familiar object properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3eb6c3-43d0-4fbb-a830-286c118218fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_model_response(payload, prediction_url):\n",
    "    raw_response = post(prediction_url, json=payload)\n",
    "    try:\n",
    "        response = raw_response.json()\n",
    "    except:\n",
    "        print(f'Failed to deserialize service response.\\n'\n",
    "              f'Status code: {raw_response.status_code}\\n')\n",
    "        #      f'Response body: {raw_response.text}')\n",
    "    try:\n",
    "        model_output = response['outputs']\n",
    "    except:\n",
    "        print(f'Failed to extract model output from service response.\\n')\n",
    "#              f'Service response: {response}')\n",
    "    return model_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4baed58-595b-49ff-86ed-c9921368a1a8",
   "metadata": {},
   "source": [
    "Let's now visualize the result as in the previous notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e452b440-078b-4e1b-a8b1-614564075144",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "roi_size = (96, 96, 96)\n",
    "sw_batch_size = 1  # TODO: use larger batch size, e.g. 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bcf1810-289d-407d-89c6-dedd7ed32189",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8e197e-ff09-49ec-abc6-a67a08bdaef9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "roi_size, sw_batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2369cf90-77ed-4541-a2fd-6f25c04611c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mydata = torch.tensor([[np.load(\"image_0.npy\")]]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e6558d-cd9b-4b05-a5d0-195f5d765d9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def deserialize(model_response):\n",
    "    response_data = model_response[0] if model_response else None\n",
    "\n",
    "    if response_data is not None:\n",
    "        # Extract relevant information from the response\n",
    "        shape = response_data.get('shape')\n",
    "        data = response_data.get('data')\n",
    "\n",
    "        if shape is not None and data is not None:\n",
    "            # Convert the data to a NumPy array\n",
    "            inferred_data_np = np.array(data)\n",
    "\n",
    "            # Check the shape of the inferred data\n",
    "            print(\"Shape of inferred_data_np:\", inferred_data_np.shape)\n",
    "\n",
    "            # Reshape the inferred data to the appropriate shape for a 3D volume\n",
    "            desired_shape = tuple(shape)\n",
    "            volume_size = np.prod(desired_shape)\n",
    "\n",
    "            if inferred_data_np.size == volume_size:\n",
    "                inferred_data_reshaped = inferred_data_np.reshape(desired_shape)\n",
    "\n",
    "                # Check the shape after reshaping\n",
    "                print(\"Shape after reshaping:\", inferred_data_reshaped.shape)\n",
    "                return torch.tensor(inferred_data_reshaped).to(device)\n",
    "            else:\n",
    "                print(\"Error: Size of inferred data does not match the volume size.\")\n",
    "        else:\n",
    "            print(\"Error: Required information (shape or data) missing in the response.\")\n",
    "    else:\n",
    "        print(\"Error: No data in the response.\")\n",
    "\n",
    "\n",
    "def badass_function(input_data):\n",
    "    print(f'input shape: {input_data.size()}')\n",
    "    #  output_data = torch_model(input_data)\n",
    "    flattened = input_data.flatten().tolist()\n",
    "    payload = serialize(flattened)\n",
    "    response = get_model_response(payload, prediction_url)\n",
    "    output_data = deserialize(response)\n",
    "    print(f'output shape: {output_data.size()}')\n",
    "    return output_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b333557-2c41-4021-abe6-1ddbb7d19df1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sliding_output = sliding_window_inference(mydata, roi_size, sw_batch_size, badass_function)\n",
    "sliding_output = sliding_output.detach().cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67878559-81f5-4e4d-8397-0923847b1146",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.imshow(sliding_output[0][1][:, :, 50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82428a73-244c-4a2e-80b6-ff10373ec6ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
